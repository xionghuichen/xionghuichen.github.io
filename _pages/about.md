---
layout: about
title: About
permalink: /
description: 

profile:
  align: right
  image: chenxh2.jpg
  address: 

news: true  # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: false  # includes social icons at the bottom of the page
---

P.hD. Student, <a href="http://lamda.nju.edu.cn/CH.MainPage.ashx">LAMDA Group</a><br>
  <a href="https://www.nju.edu.cn/EN/7f/6b/c7136a163691/page.htm">Department of Computer Science and Technology</a> <br />
  <a href="http://keysoftlab.nju.edu.cn/">National Key Laboratory for Novel Software Technology</a> 
  <a href="http://www.nju.edu.cn/">Nanjing University</a><br />
Supervisor: Prof. <a href="http://cs.nju.edu.cn/yuy/">Yang Yu</a> <br/>
Email: chenxh [at] lamda.nju.edu.cn <br/>

[ [Google scholar](https://scholar.google.com/citations?user=H5pguCYAAAAJ&hl=en)] [ [DBLP](https://dblp.org/pid/19/2969-1.html) ] [ [Research Gate](https://www.researchgate.net/profile/Xiong-Hui-Chen-2)] [ [Github](https://github.com/xionghuichen) ] [ [Twitter](https://twitter.com/xiong_hui_chen) ] [ [Zhihu](https://www.zhihu.com/people/chen-xiong-hui-10) ]

<p> Currently, I am a fourth-year PhD student of School of Artificial Intelligence in <a href="https://www.nju.edu.cn/EN/main.htm">Nanjing University</a> under the supervision of Prof. <a href="https://www.yuque.com/eyounx/home">Yang Yu</a> and also a member of <a href="https://www.lamda.nju.edu.cn/MainPage.ashx">LAMDA Group</a>, which is led by Prof. <a href="https://cs.nju.edu.cn/zhouzh/index.htm">Zhi-Hua Zhou</a>.  Before my PhD research, I received my B.Sc. degree in Department of Software Engineering in 2018 from <a href="https://www.seu.edu.cn/english/main.htm"> Southeast University </a> . In September 2018, I was admitted to study for a PhD degree in <a href="https://www.nju.edu.cn/EN/main.htm">Nanjing University</a>  under the supervision of  Prof. <a href="https://www.yuque.com/eyounx/home">Yang Yu</a> without entrance examination.  </p>


**Research interest:**  I am interested in handling challenges of Reinforcement Learning (RL) in real-world applications. In particular, I focus my research topics on <b>sim2real transfer</b>, <b>offline RL</b>, <b>causal inference for RL</b>, and <b>real-world environment reconstruction</b>. 


<!-- ### Highlights

1. Four of my papers are highly cited and ranked top 20 globally in recent 5 years in Google scholar metrics! See [here](https://zhuanlan.zhihu.com/p/421192644).
2. I wrote a popular book [迁移学习导论](http://jd92.wang/tlbook) to make it easy to learn, understand, and use transfer learning.
3. I lead the most popular transfer learning and semi-supervised learning projects on Github: [Transfer learning repo](https://github/jindongwang/transferlearning) [![Transfer learning repo](/assets/img/transferlearning-repo-star.jpg)](https://github/jindongwang/transferlearning) and  [Semi-supervised learning repo](https://github/torchssl/torchssl) [![SSL repo](/assets/img/torchssl-star.jpg)](https://github/stars/torchssl/torchssl)

#### Preprints

1. Yiqiang Chen, Wang Lu, <u>Jindong Wang</u>, Xin Qin, and Tao Qin. Federated Learning with Adaptive Batchnorm for Personalized Healthcare. arXiv preprint arXiv:2112.00734. [[arXiv](https://arxiv.org/abs/2112.00734)]
2. Wenxin Hou, Han Zhu, Yidong Wang, <u>Jindong Wang</u><sup>#</sup>, Tao Qin, Renjun Xu, and Takahiro Shinozaki. Exploiting Adapters for Cross-lingual Low-resource Speech Recognition. arXiv preprint arXiv:2105.11905. [[arXiv](https://arxiv.org/abs/2105.11905)] [[code](https://github.com/jindongwang/transferlearning/tree/master/code/ASR)]
3. <u>Jindong Wang</u>, Wenjie Feng, Chang Liu, Chaohui Yu, Mingxuan Du, Renjun Xu, Tao Qin, and Tie-Yan Liu. Learning Invariant Representations across Domains and Tasks. arXiv preprint arXiv:2103.05114. [[arXiv](https://arxiv.org/abs/2103.05114)]
4. Chaohui Yu, <u>Jindong Wang</u><sup>#</sup>, Chang Liu, Tao Qin, Renjun Xu, Wenjie Feng, Yiqiang Chen, and Tie-Yan Liu. Learning to match distributions for domain adaptation. arXiv preprint arXiv:2007.10791. [[arXiv](http://arxiv.org/abs/https://arxiv.org/abs/2007.10791)] -->
