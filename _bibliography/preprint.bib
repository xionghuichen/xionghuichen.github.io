
@article{wang20258020rulehighentropyminority,
      title={Beyond the 80/20 Rule: High-Entropy Minority Tokens Drive Effective Reinforcement Learning for LLM Reasoning}, 
      author={Shenzhi Wang and Le Yu and Chang Gao and Chujie Zheng and Shixuan Liu and Rui Lu and Kai Dang and Xiong-Hui Chen and Jianxin Yang and Zhenru Zhang and Yuqiong Liu and An Yang and Andrew Zhao and Yang Yue and Shiji Song and Bowen Yu and Gao Huang and Junyang Lin},
      year={2025},
      journal   = {ArXiv},
      volume    = {abs/2506.01939},
      url={https://arxiv.org/abs/2506.01939}, 
      abbr      = {ArXiv},
}

@article{gao2025neorl2nearrealworldbenchmarks,
      title={NeoRL-2: Near Real-World Benchmarks for Offline Reinforcement Learning with Extended Realistic Scenarios}, 
      author={Songyi Gao and Zuolin Tu and Rong-Jun Qin and Yi-Hao Sun and Xiong-Hui Chen and Yang Yu},
      year={2025},
      journal   = {ArXiv},
      volume    = {abs/2503.19267},
      url={https://arxiv.org/abs/2503.19267}, 
      abbr      = {ArXiv},
}


@article{survey-mbrl,
  author    = {Fan{-}Ming Luo and
               Tian Xu and
               Hang Lai and
               Xiong-Hui Chen and
               Weinan Zhang and
               Yang Yu},
  title     = {A Survey on Model-based Reinforcement Learning},
  journal   = {ArXiv},
  volume    = {abs/2206.09328},
  year      = {2022},  
  url       = {https://doi.org/10.48550/arXiv.2206.09328},
  abbr      = {ArXiv},
}

@article{focus,
  author    = {Zheng{-}Mao Zhu and
               Xiong-Hui Chen and
               Hong{-}Long Tian and
               Kun Zhang and
               Yang Yu},
  title     = {Offline Reinforcement Learning with Causal Structured World Models},
  journal   = {ArXiv},
  volume    = {abs/2206.01474},
  year      = {2022},
  url       = {https://doi.org/10.48550/arXiv.2206.01474},
  abbr      = {ArXiv},
}
